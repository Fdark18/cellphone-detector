{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761c3978",
   "metadata": {},
   "source": [
    "# Instalar dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f06ea644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (8.3.220)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (1.16.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (0.24.0+cu126)\n",
      "Requirement already satisfied: psutil in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (7.1.1)\n",
      "Requirement already satisfied: polars in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (1.34.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: packaging in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Requirement already satisfied: polars-runtime-32==1.34.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from polars->ultralytics) (1.34.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# Instalação de bibliotecas necessárias para o projeto.\n",
    "# Inclui YOLO, manipulação de dados e visualização.\n",
    "# \"\"\"\n",
    "!pip3 install ultralytics kagglehub pandas scikit-learn matplotlib seaborn opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691191a4",
   "metadata": {},
   "source": [
    "# Instalar CUDA (PyTorch com GPU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75eedcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jhony\\appdata\\local\\pypoetry\\cache\\virtualenvs\\lib-label-detect-cell-4prn4eew-py3.12\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "CUDA disponível: True\n",
      "GPU: NVIDIA GeForce RTX 2050\n",
      "Memória GPU: 4.00 GB\n",
      "CUDA versão: 12.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Instalação do PyTorch com suporte a CUDA 12.6.\n",
    "Permite treinamento acelerado por GPU.\n",
    "\"\"\"\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "\n",
    "# Verificar instalação CUDA\n",
    "import torch\n",
    "print(f\"CUDA disponível: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memória GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"CUDA versão: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"AVISO: GPU não detectada. Treinamento usará CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859fafa",
   "metadata": {},
   "source": [
    "# Baixar dataset do Kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Download e organização do dataset MUID-IITR.\n",
    "# \"\"\"\n",
    "# import kagglehub\n",
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# print(\"Baixando dataset...\")\n",
    "# path = kagglehub.dataset_download(\"lakshyataragi/mobilephoneusagedatasetiitr\")\n",
    "# print(f\"Dataset baixado em: {path}\")\n",
    "\n",
    "# # Mover para diretório de trabalho\n",
    "# pasta_atual = os.getcwd()\n",
    "# for arquivo in os.listdir(path):\n",
    "#     origem = os.path.join(path, arquivo)\n",
    "#     destino = os.path.join(pasta_atual, arquivo)\n",
    "    \n",
    "#     if os.path.exists(destino):\n",
    "#         if os.path.isdir(destino):\n",
    "#             shutil.rmtree(destino)\n",
    "#         else:\n",
    "#             os.remove(destino)\n",
    "    \n",
    "#     shutil.move(origem, destino)\n",
    "#     print(f\"Movido: {arquivo}\")\n",
    "\n",
    "# # Limpar cache\n",
    "# cache_path = os.path.expanduser(\"~/.cache/kagglehub\")\n",
    "# if os.path.exists(cache_path):\n",
    "#     shutil.rmtree(cache_path)\n",
    "#     print(\"\\nCache limpo\")\n",
    "\n",
    "# print(\"\\nArquivos disponíveis:\")\n",
    "# for item in sorted(os.listdir(pasta_atual)):\n",
    "#     if os.path.isdir(item) and item in ['positive', 'negative']:\n",
    "#         count = len([f for f in os.listdir(item) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "#         print(f\"  [DIR]  {item:15s} ({count} imagens)\")\n",
    "#     elif item.endswith('.csv'):\n",
    "#         print(f\"  [FILE] {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ec4d6",
   "metadata": {},
   "source": [
    "# Preparar dataset para YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792f7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Treino: 710 | Validação: 178\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preparação do dataset com verificações robustas.\n",
    "Formato YOLO com split estratificado.\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def preparar_dataset():\n",
    "    \"\"\"Prepara dataset no formato YOLO otimizado para treinamento.\"\"\"\n",
    "    \n",
    "    # Criar estrutura de diretórios\n",
    "    diretorios = [\n",
    "        'dataset/images/train',\n",
    "        'dataset/images/val',\n",
    "        'dataset/labels/train',\n",
    "        'dataset/labels/val'\n",
    "    ]\n",
    "    \n",
    "    for dir_path in diretorios:\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # Coletar imagens positive\n",
    "    positive_imgs = []\n",
    "    if os.path.exists('positive'):\n",
    "        for img in os.listdir('positive'):\n",
    "            if img.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                positive_imgs.append(('positive/' + img, 1))\n",
    "    \n",
    "    # Coletar imagens negative\n",
    "    negative_imgs = []\n",
    "    if os.path.exists('negative'):\n",
    "        for img in os.listdir('negative'):\n",
    "            if img.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                negative_imgs.append(('negative/' + img, 0))\n",
    "    \n",
    "    # Validações\n",
    "    total_positive = len(positive_imgs)\n",
    "    total_negative = len(negative_imgs)\n",
    "    \n",
    "    print(f\"Imagens positive: {total_positive}\")\n",
    "    print(f\"Imagens negative: {total_negative}\")\n",
    "    print(f\"Total:            {total_positive + total_negative}\")\n",
    "    \n",
    "    if total_positive == 0:\n",
    "        raise ValueError(\"ERRO: Nenhuma imagem positive encontrada\")\n",
    "    \n",
    "    if total_negative == 0:\n",
    "        print(\"AVISO: Nenhuma imagem negative encontrada\")\n",
    "        print(\"Modelo treinará apenas com positives\")\n",
    "    \n",
    "    # Split estratificado (80% treino, 20% validação)\n",
    "    all_imgs = positive_imgs + negative_imgs\n",
    "    train_imgs, val_imgs = train_test_split(\n",
    "        all_imgs,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=[label for _, label in all_imgs] if total_negative > 0 else None\n",
    "    )\n",
    "    \n",
    "    # Processar conjunto de treino\n",
    "    for img_path, label in train_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = f'dataset/images/train/{img_name}'\n",
    "        shutil.copy2(img_path, dest_path)\n",
    "        \n",
    "        if label == 1:\n",
    "            label_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "            label_file = f'dataset/labels/train/{label_name}'\n",
    "            with open(label_file, 'w') as f:\n",
    "                # Formato YOLO: classe x_center y_center width height (0-1)\n",
    "                f.write('0 0.5 0.5 1.0 1.0\\n')\n",
    "    \n",
    "    # Processar conjunto de validação\n",
    "    for img_path, label in val_imgs:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        dest_path = f'dataset/images/val/{img_name}'\n",
    "        shutil.copy2(img_path, dest_path)\n",
    "        \n",
    "        if label == 1:\n",
    "            label_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "            label_file = f'dataset/labels/val/{label_name}'\n",
    "            with open(label_file, 'w') as f:\n",
    "                f.write('0 0.5 0.5 1.0 1.0\\n')\n",
    "    \n",
    "    # Estatísticas\n",
    "    train_positive = sum(1 for _, label in train_imgs if label == 1)\n",
    "    val_positive = sum(1 for _, label in val_imgs if label == 1)\n",
    "    \n",
    "    print(f\"\\nDataset preparado com sucesso:\")\n",
    "    print(f\"  Treino:     {len(train_imgs)} imagens ({train_positive} positive)\")\n",
    "    print(f\"  Validação:  {len(val_imgs)} imagens ({val_positive} positive)\")\n",
    "    print(f\"  Proporção:  {len(train_imgs)/len(all_imgs)*100:.1f}% treino / {len(val_imgs)/len(all_imgs)*100:.1f}% validação\")\n",
    "    \n",
    "    return len(train_imgs), len(val_imgs)\n",
    "\n",
    "# Executar preparação\n",
    "train_count, val_count = preparar_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6c613",
   "metadata": {},
   "source": [
    "# Criar arquivo de configuração YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35ef7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo dataset.yaml criado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Arquivo de configuração do dataset.\n",
    "\"\"\"\n",
    "config_content = \"\"\"path: ./dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "nc: 1\n",
    "names: ['usando_celular']\n",
    "\"\"\"\n",
    "\n",
    "with open('dataset.yaml', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"Arquivo dataset.yaml criado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1b69c",
   "metadata": {},
   "source": [
    "# Treinar modelo YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519a928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando ambiente de treinamento...\n",
      "\n",
      "PyTorch versão: 2.9.0+cu126\n",
      "CUDA disponível: True\n",
      "GPU: NVIDIA GeForce RTX 2050\n",
      "Memória GPU: 4.00 GB\n",
      "CUDA versão: 12.6\n",
      "\n",
      "Modo: GPU ATIVADA\n",
      "\n",
      "Carregando yolov8s.pt...\n",
      "Aguarde o download se for primeira execução...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt': 100% ━━━━━━━━━━━━ 21.5MB 12.8MB/s 1.7s.6s<0.1ss\n",
      "Modelo yolov8s.pt carregado com sucesso.\n",
      "\n",
      "Iniciando treinamento:\n",
      "  Modelo:       yolov8s.pt\n",
      "  Epochs:       50\n",
      "  Batch Size:   8\n",
      "  Img Size:     640x640\n",
      "  Dispositivo:  0\n",
      "  Patience:     15\n",
      "------------------------------------------------------------\n",
      "New https://pypi.org/project/ultralytics/8.3.221 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.220  Python-3.12.0 torch-2.9.0+cu126 CUDA:0 (NVIDIA GeForce RTX 2050, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=celular_detector, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\jhony\\Documents\\lib_label_detect_cell\\runs\\detect\\celular_detector, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 14.4MB/s 0.4s.4s<0.0s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 45.122.4 MB/s, size: 479.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\jhony\\Documents\\lib_label_detect_cell\\dataset\\labels\\train... 431 images, 279 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 710/710 477.8it/s 1.5s0.2s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\jhony\\Documents\\lib_label_detect_cell\\dataset\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 20.317.1 MB/s, size: 400.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\jhony\\Documents\\lib_label_detect_cell\\dataset\\labels\\val... 109 images, 69 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 178/178 415.7it/s 0.4s.3s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\jhony\\Documents\\lib_label_detect_cell\\dataset\\labels\\val.cache\n",
      "Plotting labels to C:\\Users\\jhony\\Documents\\lib_label_detect_cell\\runs\\detect\\celular_detector\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\jhony\\Documents\\lib_label_detect_cell\\runs\\detect\\celular_detector\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      2.08G     0.4853      2.011      1.153         15        640: 100% ━━━━━━━━━━━━ 89/89 1.3it/s 1:080.7s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 12/12 1.1it/s 11.0s0.9s\n",
      "                   all        178        109      0.171      0.404      0.141     0.0634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      2.18G     0.4335       1.21      1.067         17        640: 56% ━━━━━━╸───── 50/89 2.1it/s 32.6s<18.7s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Treinar modelo com configurações otimizadas para Windows\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset.yaml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcelular_detector\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# IMPORTANTE: 0 para Windows (desabilita multiprocessing)\u001b[39;49;00m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mplots\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTreinamento concluído com sucesso.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     83\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModelo salvo em: runs/detect/celular_detector/weights/best.pt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\engine\\model.py:800\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    797\u001b[39m     \u001b[38;5;28mself\u001b[39m.trainer.model = \u001b[38;5;28mself\u001b[39m.trainer.get_model(weights=\u001b[38;5;28mself\u001b[39m.model \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg=\u001b[38;5;28mself\u001b[39m.model.yaml)\n\u001b[32m    798\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m--> \u001b[39m\u001b[32m800\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:238\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    235\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:399\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    397\u001b[39m     pbar = TQDM(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader), total=nb)\n\u001b[32m    398\u001b[39m \u001b[38;5;28mself\u001b[39m.tloss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mon_train_batch_start\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Warmup\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\utils\\tqdm.py:347\u001b[39m, in \u001b[36mTQDM.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mNoneType\u001b[39m\u001b[33m'\u001b[39m\u001b[33m object is not iterable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\build.py:77\u001b[39m, in \u001b[36mInfiniteDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an iterator that yields indefinitely from the underlying iterator.\"\"\"\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\base.py:381\u001b[39m, in \u001b[36mBaseDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    380\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return transformed label information for given index.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_image_and_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\augment.py:204\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03mApply a series of transformations to input data.\u001b[39;00m\n\u001b[32m    188\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \u001b[33;03m    >>> transformed_data = compose(input_data)\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     data = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\augment.py:204\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03mApply a series of transformations to input data.\u001b[39;00m\n\u001b[32m    188\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m \u001b[33;03m    >>> transformed_data = compose(input_data)\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     data = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\augment.py:407\u001b[39m, in \u001b[36mBaseMixTransform.__call__\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m    405\u001b[39m labels = \u001b[38;5;28mself\u001b[39m._update_label_text(labels)\n\u001b[32m    406\u001b[39m \u001b[38;5;66;03m# Mosaic, CutMix or MixUp\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mix_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m labels.pop(\u001b[33m\"\u001b[39m\u001b[33mmix_labels\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\augment.py:595\u001b[39m, in \u001b[36mMosaic._mix_transform\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m    592\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m labels.get(\u001b[33m\"\u001b[39m\u001b[33mrect_shape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mrect and mosaic are mutually exclusive.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(labels.get(\u001b[33m\"\u001b[39m\u001b[33mmix_labels\u001b[39m\u001b[33m\"\u001b[39m, [])), \u001b[33m\"\u001b[39m\u001b[33mThere are no other images for mosaic augment.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m     \u001b[38;5;28mself\u001b[39m._mosaic3(labels) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n == \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mosaic4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n == \u001b[32m4\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mosaic9(labels)\n\u001b[32m    596\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\ultralytics\\data\\augment.py:692\u001b[39m, in \u001b[36mMosaic._mosaic4\u001b[39m\u001b[34m(self, labels)\u001b[39m\n\u001b[32m    690\u001b[39m \u001b[38;5;66;03m# Place img in img4\u001b[39;00m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:  \u001b[38;5;66;03m# top left\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m692\u001b[39m     img4 = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m114\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# base image with 4 tiles\u001b[39;00m\n\u001b[32m    693\u001b[39m     x1a, y1a, x2a, y2a = \u001b[38;5;28mmax\u001b[39m(xc - w, \u001b[32m0\u001b[39m), \u001b[38;5;28mmax\u001b[39m(yc - h, \u001b[32m0\u001b[39m), xc, yc  \u001b[38;5;66;03m# xmin, ymin, xmax, ymax (large image)\u001b[39;00m\n\u001b[32m    694\u001b[39m     x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  \u001b[38;5;66;03m# xmin, ymin, xmax, ymax (small image)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jhony\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\lib-label-detect-cell-4PrN4EeW-py3.12\\Lib\\site-packages\\numpy\\core\\numeric.py:330\u001b[39m, in \u001b[36mfull\u001b[39m\u001b[34m(shape, fill_value, dtype, order, like)\u001b[39m\n\u001b[32m    328\u001b[39m     dtype = fill_value.dtype\n\u001b[32m    329\u001b[39m a = empty(shape, dtype, order)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[43mmultiarray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munsafe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Treinamento otimizado para Linux com RTX 2050 4GB.\n",
    "Configurações ajustadas.\n",
    "\"\"\"\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ===== CONFIGURAÇÕES =====\n",
    "TRAIN_GPU = 1\n",
    "EPOCHS = 100                    # Mais epochs para melhor resultado\n",
    "BATCH_SIZE = 12                 # Otimizado para 4GB em Linux\n",
    "IMG_SIZE = 640\n",
    "PATIENCE = 20\n",
    "MODELO_BASE = 'yolov8m.pt'      # Modelo medium para melhor precisão\n",
    "\n",
    "# Verificar ambiente\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURAÇÃO DE TREINAMENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"Sistema:             Linux\")\n",
    "print(f\"PyTorch:             {torch.__version__}\")\n",
    "print(f\"CUDA disponível:     {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    \n",
    "    print(f\"GPU:                 {gpu_name}\")\n",
    "    print(f\"Memória GPU:         {gpu_mem:.2f} GB\")\n",
    "    print(f\"CUDA versão:         {torch.version.cuda}\")\n",
    "    print(f\"cuDNN:               {torch.backends.cudnn.version()}\")\n",
    "    \n",
    "    # Otimizações CUDA\n",
    "    torch.backends.cudnn.benchmark = True      # Auto-tuning\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    \n",
    "    device = 0\n",
    "    print(\"\\nOtimizações CUDA:    ATIVADAS\")\n",
    "    print(\"  - cuDNN benchmark: True\")\n",
    "    print(\"  - TF32:            True\")\n",
    "    \n",
    "    # Ajustar batch baseado na memória e modelo\n",
    "    if gpu_mem < 6:\n",
    "        if 'm' in MODELO_BASE:\n",
    "            BATCH_SIZE = 12\n",
    "        elif 'l' in MODELO_BASE or 'x' in MODELO_BASE:\n",
    "            BATCH_SIZE = 8\n",
    "        else:\n",
    "            BATCH_SIZE = 16\n",
    "        print(f\"\\nBatch ajustado:      {BATCH_SIZE}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"\\nERRO: GPU não detectada!\")\n",
    "    print(\"Execute: nvidia-smi\")\n",
    "    raise RuntimeError(\"GPU NVIDIA não encontrada\")\n",
    "\n",
    "# Carregar modelo\n",
    "print(f\"\\nCarregando {MODELO_BASE}...\")\n",
    "try:\n",
    "    model = YOLO(MODELO_BASE)\n",
    "    print(f\"Modelo carregado: {MODELO_BASE}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO: {e}\")\n",
    "    raise\n",
    "\n",
    "# Configuração final\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PARÂMETROS DE TREINAMENTO\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Modelo:              {MODELO_BASE}\")\n",
    "print(f\"Epochs:              {EPOCHS}\")\n",
    "print(f\"Batch Size:          {BATCH_SIZE}\")\n",
    "print(f\"Image Size:          {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Dispositivo:         GPU {device}\")\n",
    "print(f\"Workers:             8 (Linux multiprocessing)\")\n",
    "print(f\"Patience:            {PATIENCE}\")\n",
    "print(f\"AMP:                 Habilitado\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Treinar com configurações otimizadas para Linux\n",
    "try:\n",
    "    results = model.train(\n",
    "        data='dataset.yaml',\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMG_SIZE,\n",
    "        batch=BATCH_SIZE,\n",
    "        patience=PATIENCE,\n",
    "        device=device,\n",
    "        name='celular_detector',\n",
    "        \n",
    "        # Performance\n",
    "        workers=8,                      # Linux permite multiprocessing\n",
    "        amp=True,                       # Automatic Mixed Precision\n",
    "        \n",
    "        # Otimizações\n",
    "        cache=True,                     # Cache imagens em RAM\n",
    "        optimizer='AdamW',              # Otimizador mais eficiente\n",
    "        cos_lr=True,                    # Cosine learning rate\n",
    "        \n",
    "        # Augmentations otimizadas\n",
    "        hsv_h=0.015,\n",
    "        hsv_s=0.7,\n",
    "        hsv_v=0.4,\n",
    "        degrees=10.0,\n",
    "        translate=0.1,\n",
    "        scale=0.5,\n",
    "        shear=0.0,\n",
    "        perspective=0.0,\n",
    "        flipud=0.0,\n",
    "        fliplr=0.5,\n",
    "        mosaic=1.0,\n",
    "        mixup=0.1,\n",
    "        \n",
    "        # Configurações\n",
    "        verbose=True,\n",
    "        exist_ok=True,\n",
    "        plots=True,\n",
    "        save=True,\n",
    "        val=True,\n",
    "        save_period=10,                 # Salvar checkpoint a cada 10 epochs\n",
    "        \n",
    "        # Callbacks\n",
    "        patience=PATIENCE,\n",
    "        close_mosaic=int(EPOCHS * 0.8)  # Desabilitar mosaic nos últimos 20%\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TREINAMENTO CONCLUÍDO\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Modelo salvo em: runs/detect/celular_detector/weights/best.pt\")\n",
    "    print(f\"Logs em:         runs/detect/celular_detector/\")\n",
    "    \n",
    "    # Avaliar modelo\n",
    "    print(\"\\nAvaliando modelo...\")\n",
    "    metrics = model.val(\n",
    "        data='dataset.yaml',\n",
    "        workers=8,\n",
    "        batch=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Exibir métricas\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MÉTRICAS DE DESEMPENHO\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Modelo:              {MODELO_BASE}\")\n",
    "    print(f\"mAP50:               {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95:            {metrics.box.map:.4f}\")\n",
    "    print(f\"Precision:           {metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall:              {metrics.box.mr:.4f}\")\n",
    "    \n",
    "    if (metrics.box.mp + metrics.box.mr) > 0:\n",
    "        f1 = 2 * (metrics.box.mp * metrics.box.mr) / (metrics.box.mp + metrics.box.mr)\n",
    "        print(f\"F1-Score:            {f1:.4f}\")\n",
    "    \n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Avaliação qualitativa\n",
    "    if metrics.box.map50 > 0.85:\n",
    "        print(\"\\nRESULTADO: Excelente (>85%)\")\n",
    "    elif metrics.box.map50 > 0.70:\n",
    "        print(\"\\nRESULTADO: Bom (70-85%)\")\n",
    "    elif metrics.box.map50 > 0.50:\n",
    "        print(\"\\nRESULTADO: Aceitável (50-70%)\")\n",
    "    else:\n",
    "        print(\"\\nRESULTADO: Baixo (<50%) - Revisar dataset\")\n",
    "    \n",
    "    # Limpar cache GPU\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nCache GPU limpo\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    error_msg = str(e).lower()\n",
    "    \n",
    "    if \"out of memory\" in error_msg:\n",
    "        print(\"\\nERRO: Memória GPU insuficiente\")\n",
    "        print(\"\\nREDUZIR:\")\n",
    "        print(f\"  BATCH_SIZE = {BATCH_SIZE // 2}\")\n",
    "        print(f\"  IMG_SIZE = 416\")\n",
    "        print(f\"  cache=False\")\n",
    "    else:\n",
    "        print(f\"\\nERRO: {e}\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    raise\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nTreinamento interrompido pelo usuário\")\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nERRO inesperado: {e}\")\n",
    "    torch.cuda.empty_cache()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f719364",
   "metadata": {},
   "source": [
    "# Testar modelo em imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Teste do modelo treinado com visualização.\n",
    "\"\"\"\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "# Carregar melhor modelo\n",
    "model = YOLO('runs/detect/celular_detector/weights/best.pt')\n",
    "\n",
    "# Testar em imagens\n",
    "test_images = []\n",
    "if os.path.exists('positive'):\n",
    "    test_images = [f'positive/{img}' for img in os.listdir('positive')[:5]\n",
    "                   if img.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "print(f\"Testando em {len(test_images)} imagens...\\n\")\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = model(img_path, conf=0.5, verbose=False)\n",
    "    \n",
    "    output_name = f\"resultado_{os.path.basename(img_path)}\"\n",
    "    results[0].save(output_name)\n",
    "    \n",
    "    num_det = len(results[0].boxes)\n",
    "    print(f\"{os.path.basename(img_path)}: {num_det} detecções\")\n",
    "    \n",
    "    if num_det > 0:\n",
    "        conf = results[0].boxes.conf[0].item()\n",
    "        print(f\"  Confiança: {conf:.2%}\")\n",
    "    \n",
    "    display(Image(output_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3578bb",
   "metadata": {},
   "source": [
    "# Métricas avançadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Análise detalhada com matriz de confusão e curvas.\n",
    "\"\"\"\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = YOLO('runs/detect/celular_detector/weights/best.pt')\n",
    "\n",
    "print(\"Calculando métricas avançadas...\\n\")\n",
    "\n",
    "# Coletar predições\n",
    "val_images = [os.path.join('dataset/images/val', img)\n",
    "              for img in os.listdir('dataset/images/val')]\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "print(f\"Processando {len(val_images)} imagens...\")\n",
    "for i, img_path in enumerate(val_images):\n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  {i+1}/{len(val_images)}\")\n",
    "    \n",
    "    # Ground truth\n",
    "    img_name = os.path.basename(img_path)\n",
    "    label_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "    label_path = os.path.join('dataset/labels/val', label_name)\n",
    "    \n",
    "    has_label = os.path.exists(label_path) and os.path.getsize(label_path) > 0\n",
    "    y_true.append(1 if has_label else 0)\n",
    "    \n",
    "    # Predição\n",
    "    results = model(img_path, conf=0.5, verbose=False)\n",
    "    y_pred.append(1 if len(results[0].boxes) > 0 else 0)\n",
    "\n",
    "print(f\"Total: {len(val_images)}\\n\")\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Sem Celular', 'Com Celular'],\n",
    "            yticklabels=['Sem Celular', 'Com Celular'],\n",
    "            annot_kws={'size': 14},\n",
    "            cbar_kws={'label': 'Quantidade'})\n",
    "plt.title('Matriz de Confusão - Detecção de Uso de Celular',\n",
    "          fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('Valor Real', fontsize=13)\n",
    "plt.xlabel('Predição do Modelo', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.savefig('matriz_confusao.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MATRIZ DE CONFUSÃO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Verdadeiros Negativos (TN):  {cm[0,0]:5d}  (Correto: SEM)\")\n",
    "print(f\"Falsos Positivos (FP):       {cm[0,1]:5d}  (Erro: Falso alarme)\")\n",
    "print(f\"Falsos Negativos (FN):       {cm[1,0]:5d}  (Erro: Não detectou)\")\n",
    "print(f\"Verdadeiros Positivos (TP):  {cm[1,1]:5d}  (Correto: COM)\")\n",
    "\n",
    "# Curva Precision-Recall\n",
    "thresholds = np.arange(0.1, 1.0, 0.05)\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "print(f\"\\nCalculando curva P-R ({len(thresholds)} pontos)...\")\n",
    "for thresh in thresholds:\n",
    "    y_pred_t = []\n",
    "    for img_path in val_images:\n",
    "        results = model(img_path, conf=thresh, verbose=False)\n",
    "        y_pred_t.append(1 if len(results[0].boxes) > 0 else 0)\n",
    "    \n",
    "    tp = sum((yt == 1 and yp == 1) for yt, yp in zip(y_true, y_pred_t))\n",
    "    fp = sum((yt == 0 and yp == 1) for yt, yp in zip(y_true, y_pred_t))\n",
    "    fn = sum((yt == 1 and yp == 0) for yt, yp in zip(y_true, y_pred_t))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.plot(recalls, precisions, 'b-', linewidth=3, marker='o', markersize=5)\n",
    "plt.fill_between(recalls, precisions, alpha=0.2)\n",
    "plt.xlabel('Recall (Sensibilidade)', fontsize=13)\n",
    "plt.ylabel('Precision (Precisão)', fontsize=13)\n",
    "plt.title('Curva Precision-Recall', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "\n",
    "for i, thresh in enumerate(thresholds[::3]):\n",
    "    idx = i * 3\n",
    "    if idx < len(recalls):\n",
    "        plt.annotate(f'{thresh:.2f}',\n",
    "                    xy=(recalls[idx], precisions[idx]),\n",
    "                    xytext=(8, 8), textcoords='offset points',\n",
    "                    fontsize=9, alpha=0.7,\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('precision_recall_curve.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Relatório\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELATÓRIO DE CLASSIFICAÇÃO\")\n",
    "print(\"=\"*60)\n",
    "report = classification_report(y_true, y_pred,\n",
    "                               target_names=['Sem Celular', 'Com Celular'],\n",
    "                               digits=4)\n",
    "print(report)\n",
    "\n",
    "# Resumo\n",
    "accuracy = (cm[0,0] + cm[1,1]) / cm.sum() if cm.sum() > 0 else 0\n",
    "specificity = cm[0,0] / (cm[0,0] + cm[0,1]) if (cm[0,0] + cm[0,1]) > 0 else 0\n",
    "sensitivity = cm[1,1] / (cm[1,1] + cm[1,0]) if (cm[1,1] + cm[1,0]) > 0 else 0\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RESUMO FINAL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Acurácia (Accuracy):     {accuracy:.2%}\")\n",
    "print(f\"Especificidade:          {specificity:.2%}  (Taxa de TN)\")\n",
    "print(f\"Sensibilidade (Recall):  {sensitivity:.2%}  (Taxa de TP)\")\n",
    "print(f\"Total Imagens:           {len(y_true)}\")\n",
    "print(f\"\\nGráficos salvos:\")\n",
    "print(f\"  - matriz_confusao.png\")\n",
    "print(f\"  - precision_recall_curve.png\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lib-label-detect-cell-4PrN4EeW-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
